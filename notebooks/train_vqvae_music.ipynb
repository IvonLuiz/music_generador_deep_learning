{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../src/modeling')\n",
    "\n",
    "from vq_vae import VQ_VAE\n",
    "from train_vq import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../src')\n",
    "\n",
    "from generate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECTROGRAMS_SAVE_DIR = \"./data/processed/maestro_spectrograms/\"\n",
    "SPECTROGRAMS_PATH = \"../data/processed/maestro_spectrograms/\"\n",
    "\n",
    "LEARNING_RATE = 0.0005\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_maestro(path):\n",
    "    x_train = []\n",
    "    file_paths = []\n",
    "    \n",
    "    for root, _, file_names in os.walk(path):\n",
    "        for file_name in file_names:\n",
    "            if file_name.endswith(\".npy\"):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                spectrogram = np.load(file_path) # (n_bins, n_frames, 1)\n",
    "                x_train.append(spectrogram)\n",
    "                file_paths.append(file_path)\n",
    "    \n",
    "    x_train = np.array(x_train)\n",
    "    x_train = x_train[..., np.newaxis] # -> (3000, 256, 64, 1)\n",
    "\n",
    "    return x_train, file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, _ = load_maestro(SPECTROGRAMS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163, 256, 1801, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_variance = np.var(x_train / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "VQVAE = VQ_VAE(\n",
    "    input_shape=(256, x_train.shape[2], 1),\n",
    "    conv_filters=(512, 256, 128, 64, 32),\n",
    "    conv_kernels=(3, 3, 3, 3, 3),\n",
    "    conv_strides=(2, 2, 2, 2, (2, 1)),\n",
    "    data_variance=data_variance,\n",
    "    embeddings_size=256,\n",
    "    latent_space_dim=128\n",
    ")\n",
    "# VQVAE.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "VQVAE.compile(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 1801 and 1808 for '{{node sub}} = Sub[T=DT_FLOAT](data, vq_vae_6_1/decoder_1/sigmoid_output_1/Sigmoid)' with input shapes: [?,256,1801,1], [?,256,1808,1].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mVQVAE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Code\\Data Science\\Projects\\music_generador_deep_learning\\notebooks\\../src/modeling\\vq_vae.py:117\u001b[0m, in \u001b[0;36mVQ_VAE.train\u001b[1;34m(self, x_train, batch_size, num_epochs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_train, batch_size, num_epochs):\n\u001b[0;32m    114\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    Trains the VQ-VAE model on the given data.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m             \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m             \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m             \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Code\\Data Science\\Projects\\music_generador_deep_learning\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Code\\Data Science\\Projects\\music_generador_deep_learning\\notebooks\\../src/modeling\\vq_vae.py:146\u001b[0m, in \u001b[0;36mVQ_VAE.train_step\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    142\u001b[0m     reconstructions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x)\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# Calculate the losses.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     reconstruction_loss \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 146\u001b[0m         tf\u001b[38;5;241m.\u001b[39mreduce_mean((\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreconstructions\u001b[49m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_variance\n\u001b[0;32m    147\u001b[0m     )\n\u001b[0;32m    148\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m reconstruction_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# Backpropagation.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 1801 and 1808 for '{{node sub}} = Sub[T=DT_FLOAT](data, vq_vae_6_1/decoder_1/sigmoid_output_1/Sigmoid)' with input shapes: [?,256,1801,1], [?,256,1808,1]."
     ]
    }
   ],
   "source": [
    "VQVAE.train(x_train, BATCH_SIZE, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully in folder: ../../model/vq_vae_maestro2011\n"
     ]
    }
   ],
   "source": [
    "VQVAE.save(\"../../model/vq_vae_maestro2011\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_generator = SoundGenerator(VQVAE, HOP_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_MAX_VALUES_PATH = \"../data/raw/maestro-v3.0.0/2011/min_max_values.pkl\"\n",
    "SAVE_DIR_ORIGINAL = \"../samples/vq_vae_maestro2011/original/\"\n",
    "SAVE_DIR_GENERATED = \"../samples/vq_vae_maestro2011/generated/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spectrograms + min max values\n",
    "with open(MIN_MAX_VALUES_PATH, \"rb\") as f:\n",
    "    min_max_values = pickle.load(f)\n",
    "specs, file_paths = load_fsdd(SPECTROGRAMS_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/processed/maestro_spectrograms/MIDI-Unprocessed_09_R1_2011_MID--AUDIO_R1-D3_12_Track12_wav.wav.npy', './data/processed/maestro_spectrograms/MIDI-Unprocessed_23_R1_2011_MID--AUDIO_R1-D9_03_Track03_wav.wav.npy', './data/processed/maestro_spectrograms/MIDI-Unprocessed_10_R1_2011_MID--AUDIO_R1-D4_05_Track05_wav.wav.npy', './data/processed/maestro_spectrograms/MIDI-Unprocessed_01_R1_2011_MID--AUDIO_R1-D1_06_Track06_wav.wav.npy', './data/processed/maestro_spectrograms/MIDI-Unprocessed_16_R2_2011_MID--AUDIO_R2-D4_09_Track09_wav.wav.npy']\n",
      "[{'min': -84.00179, 'max': -4.001792}, {'min': -83.94058, 'max': -3.9405813}, {'min': -88.7076, 'max': -8.707606}, {'min': -48.742622, 'max': 31.257378}, {'min': -82.653946, 'max': -2.6539454}]\n"
     ]
    }
   ],
   "source": [
    "# Sample spectrograms + min max values\n",
    "\n",
    "file_paths_selected = file_paths\n",
    "\n",
    "sampled_indexes = np.random.choice(range(len(specs)), 5)\n",
    "sampled_spectrogrmas = specs[sampled_indexes]\n",
    "\n",
    "file_paths_selected = [file_paths_selected[index] for index in sampled_indexes]\n",
    "file_paths_selected =  list(map(lambda st: str.replace(st, \"\\\\\", \"/\"), file_paths_selected))\n",
    "file_paths_selected =  list(map(lambda st: str.replace(st, \"..\", \".\"), file_paths_selected))\n",
    "\n",
    "sampled_min_max_values = [min_max_values[file_path] for file_path in file_paths_selected]\n",
    "\n",
    "print(file_paths_selected)\n",
    "print(sampled_min_max_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate audio for sampled spectrograms\n",
    "signals, _ = sound_generator.generate(sampled_spectrogrmas, sampled_min_max_values)\n",
    "\n",
    "original_signals = sound_generator.convert_spectrograms_to_audio(sampled_spectrogrmas, sampled_min_max_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_signals(signals, SAVE_DIR_GENERATED)\n",
    "save_signals(original_signals, SAVE_DIR_ORIGINAL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
